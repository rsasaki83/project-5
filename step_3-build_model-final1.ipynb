{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.project_5 import load_data_from_database, make_data_dict, general_model, general_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: EACH OF THESE SHOULD BE WRITTEN SOLELY WITH REGARD TO STEP 3 - Build Model**\n",
    "\n",
    "### Domain and Data\n",
    "\n",
    "**TODO:** Write a simple statement about the domain of your problem and the dataset upon which you will be working. \n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "**TODO:** Write a simple problem statement with regard to building your model. As this is the final step, you may want to be a bit more \"global\" here.\n",
    "\n",
    "### Solution Statement\n",
    "\n",
    "**TODO:** Write a simple solution statement with regard to building your model.\n",
    "\n",
    "### Metric\n",
    "\n",
    "**TODO**: Write a statement about the metric you will be using. \n",
    "\n",
    "### Benchmark\n",
    "\n",
    "**TODO**: This should refer to Step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Implement the following code pipeline using the functions you write in `lib/project_5.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/build_model.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0      0       485       477       537       479       452       471   \n",
       "1      1       483       458       460       487       587       475   \n",
       "2      2       487       542       499       468       448       471   \n",
       "3      3       480       491       510       485       495       472   \n",
       "4      4       484       502       528       489       466       481   \n",
       "\n",
       "   feat_006  feat_007  feat_008  ...    feat_491  feat_492  feat_493  \\\n",
       "0       491       476       475  ...         481       477       485   \n",
       "1       526       479       485  ...         478       487       338   \n",
       "2       442       478       480  ...         481       492       650   \n",
       "3       417       474       502  ...         480       474       572   \n",
       "4       402       478       487  ...         479       452       435   \n",
       "\n",
       "   feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  label  \n",
       "0       511       485       481       479       475       496     -1  \n",
       "1       513       486       483       492       510       517     -1  \n",
       "2       506       501       480       489       499       498     -1  \n",
       "3       454       469       475       482       494       461      1  \n",
       "4       486       508       481       504       495       511      1  \n",
       "\n",
       "[5 rows x 502 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_feat_df= load_data_from_database()\n",
    "madelon_feat_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=madelon_feat_df.drop(['index', 'label'], axis=1)\n",
    "y=madelon_feat_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test':       feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       " 1938       478       468       457       491       563       491       471   \n",
       " 427        487       456       475       478       475       473       528   \n",
       " 548        481       496       494       478       461       474       484   \n",
       " 1715       476       416       538       485       509       477       463   \n",
       " 390        485       488       526       495       558       474       453   \n",
       " 930        480       505       494       471       470       463       511   \n",
       " 1107       478       467       532       493       495       475       504   \n",
       " 1605       479       474       554       475       472       477       483   \n",
       " 110        482       458       550       493       454       479       503   \n",
       " 1296       479       503       435       475       466       464       448   \n",
       " 70         477       462       476       485       503       482       439   \n",
       " 1201       480       495       489       497       500       490       483   \n",
       " 689        474       440       537       472       496       483       444   \n",
       " 38         476       490       549       481       484       475       498   \n",
       " 810        488       472       507       489       493       478       437   \n",
       " 407        489       485       495       486       518       467       556   \n",
       " 1821       491       491       488       480       467       484       433   \n",
       " 1794       486       444       535       477       563       477       458   \n",
       " 230        480       433       454       498       422       477       438   \n",
       " 1835       476       508       530       476       512       480       528   \n",
       " 397        488       513       457       489       518       476       502   \n",
       " 723        479       495       499       481       466       481       445   \n",
       " 360        498       471       472       484       480       477       445   \n",
       " 1775       481       511       535       486       571       485       481   \n",
       " 180        487       484       533       477       512       482       494   \n",
       " 589        482       491       515       484       524       479       493   \n",
       " 1561       486       496       482       463       490       479       490   \n",
       " 906        477       448       514       475       542       476       394   \n",
       " 380        492       480       456       478       574       480       557   \n",
       " 1732       479       480       505       500       465       480       500   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 617        486       471       463       485       465       484       557   \n",
       " 1224       476       465       509       497       496       485       491   \n",
       " 1750       478       515       518       486       482       478       506   \n",
       " 1706       486       506       498       473       482       481       500   \n",
       " 1655       482       449       489       482       562       467       482   \n",
       " 645        475       493       539       491       417       478       480   \n",
       " 124        483       451       495       485       453       488       435   \n",
       " 1763       480       500       443       486       495       480       448   \n",
       " 1720       477       500       495       475       481       483       400   \n",
       " 1964       482       462       483       480       519       482       458   \n",
       " 218        479       472       583       497       435       473       562   \n",
       " 322        478       455       537       477       527       488       478   \n",
       " 1255       483       482       465       456       481       492       504   \n",
       " 1180       486       537       534       489       386       474       388   \n",
       " 1038       484       476       524       487       495       478       538   \n",
       " 968        494       476       461       463       506       480       463   \n",
       " 493        490       463       436       474       498       485       548   \n",
       " 1438       473       437       567       476       467       485       495   \n",
       " 262        484       487       470       485       492       474       401   \n",
       " 145        478       492       497       482       383       482       555   \n",
       " 1610       477       516       510       506       510       475       611   \n",
       " 860        481       492       478       470       490       468       453   \n",
       " 1819       475       456       537       472       562       484       492   \n",
       " 1989       486       473       525       486       443       477       458   \n",
       " 1589       487       467       486       484       530       492       440   \n",
       " 49         473       435       549       489       476       475       501   \n",
       " 120        487       457       503       496       547       480       433   \n",
       " 1508       475       520       506       492       495       470       479   \n",
       " 984        482       451       567       471       487       487       433   \n",
       " 837        485       493       491       491       509       478       468   \n",
       " \n",
       "       feat_007  feat_008  feat_009    ...     feat_490  feat_491  feat_492  \\\n",
       " 1938       476       472       486    ...          439       486       514   \n",
       " 427        477       467       487    ...          486       476       460   \n",
       " 548        477       478       489    ...          491       478       474   \n",
       " 1715       477       483       480    ...          483       486       428   \n",
       " 390        475       474       476    ...          488       476       438   \n",
       " 930        479       490       480    ...          462       476       514   \n",
       " 1107       477       480       476    ...          526       473       457   \n",
       " 1605       478       487       491    ...          469       476       475   \n",
       " 110        477       476       467    ...          483       484       470   \n",
       " 1296       480       478       488    ...          456       476       481   \n",
       " 70         475       494       472    ...          459       474       493   \n",
       " 1201       476       486       484    ...          465       481       461   \n",
       " 689        478       477       481    ...          497       468       533   \n",
       " 38         476       487       480    ...          503       481       499   \n",
       " 810        476       466       487    ...          488       473       489   \n",
       " 407        477       459       472    ...          491       480       497   \n",
       " 1821       476       472       481    ...          494       478       437   \n",
       " 1794       476       474       471    ...          503       482       472   \n",
       " 230        476       489       480    ...          494       486       469   \n",
       " 1835       476       483       467    ...          471       476       475   \n",
       " 397        477       469       479    ...          510       485       469   \n",
       " 723        477       492       479    ...          488       480       492   \n",
       " 360        477       473       477    ...          457       477       465   \n",
       " 1775       480       497       486    ...          498       477       487   \n",
       " 180        474       486       478    ...          497       482       474   \n",
       " 589        476       500       481    ...          496       476       484   \n",
       " 1561       476       478       473    ...          494       479       528   \n",
       " 906        476       501       471    ...          439       479       471   \n",
       " 380        476       480       476    ...          478       476       476   \n",
       " 1732       477       507       477    ...          493       477       457   \n",
       " ...        ...       ...       ...    ...          ...       ...       ...   \n",
       " 617        476       483       483    ...          461       480       484   \n",
       " 1224       477       505       478    ...          442       485       524   \n",
       " 1750       478       462       464    ...          481       481       485   \n",
       " 1706       478       482       477    ...          506       479       483   \n",
       " 1655       474       483       467    ...          508       480       428   \n",
       " 645        475       473       471    ...          485       473       491   \n",
       " 124        477       490       475    ...          474       474       473   \n",
       " 1763       478       516       479    ...          493       479       472   \n",
       " 1720       475       509       472    ...          509       479       469   \n",
       " 1964       478       501       493    ...          497       472       480   \n",
       " 218        475       450       478    ...          512       483       472   \n",
       " 322        476       487       482    ...          496       477       500   \n",
       " 1255       480       482       481    ...          479       475       511   \n",
       " 1180       477       506       488    ...          500       472       488   \n",
       " 1038       476       475       477    ...          490       486       492   \n",
       " 968        477       509       483    ...          500       471       532   \n",
       " 493        477       466       479    ...          499       476       448   \n",
       " 1438       476       490       487    ...          523       484       531   \n",
       " 262        475       488       475    ...          456       481       470   \n",
       " 145        477       507       479    ...          496       482       474   \n",
       " 1610       478       500       480    ...          480       470       491   \n",
       " 860        477       475       470    ...          474       475       453   \n",
       " 1819       477       492       485    ...          492       476       505   \n",
       " 1989       475       486       481    ...          505       482       536   \n",
       " 1589       478       492       475    ...          516       483       468   \n",
       " 49         476       511       488    ...          464       481       519   \n",
       " 120        477       499       485    ...          488       481       477   \n",
       " 1508       476       498       479    ...          480       479       534   \n",
       " 984        476       493       487    ...          499       486       497   \n",
       " 837        479       471       486    ...          506       478       477   \n",
       " \n",
       "       feat_493  feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  \n",
       " 1938       626       456       538       467       491       454       468  \n",
       " 427        622       457       505       480       479       483       461  \n",
       " 548        532       517       507       478       478       505       463  \n",
       " 1715       647       514       524       483       464       519       485  \n",
       " 390        409       481       482       473       494       531       527  \n",
       " 930        548       468       446       486       471       494       522  \n",
       " 1107       419       543       595       473       484       459       528  \n",
       " 1605       550       552       519       470       485       564       497  \n",
       " 110        483       421       517       482       475       514       501  \n",
       " 1296       561       472       540       491       476       524       475  \n",
       " 70         359       575       533       490       489       581       478  \n",
       " 1201       412       511       530       481       491       525       516  \n",
       " 689        533       484       565       477       513       508       519  \n",
       " 38         608       486       519       475       487       446       487  \n",
       " 810        555       530       465       485       477       532       530  \n",
       " 407        584       522       510       473       469       587       470  \n",
       " 1821       454       456       488       478       483       532       486  \n",
       " 1794       407       484       527       463       501       514       500  \n",
       " 230        722       509       526       485       445       502       472  \n",
       " 1835       404       504       492       486       490       478       524  \n",
       " 397        642       540       475       482       471       519       521  \n",
       " 723        482       494       517       480       483       487       479  \n",
       " 360        567       407       547       481       464       387       511  \n",
       " 1775       540       463       591       487       512       579       549  \n",
       " 180        399       521       479       477       492       511       453  \n",
       " 589        400       486       487       480       487       439       517  \n",
       " 1561       394       456       571       470       495       454       465  \n",
       " 906        439       529       458       461       482       500       536  \n",
       " 380        586       482       507       471       477       539       513  \n",
       " 1732       724       490       570       478       494       530       507  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 617        335       506       519       479       496       504       513  \n",
       " 1224       455       502       500       472       511       518       500  \n",
       " 1750       393       424       568       473       490       483       496  \n",
       " 1706       603       504       493       475       505       477       477  \n",
       " 1655       571       460       525       469       491       485       449  \n",
       " 645        576       527       494       478       493       499       464  \n",
       " 124        377       454       531       485       491       524       497  \n",
       " 1763       558       522       508       483       501       488       487  \n",
       " 1720       496       550       520       475       488       470       524  \n",
       " 1964       574       470       440       474       480       527       472  \n",
       " 218        351       471       548       470       499       539       495  \n",
       " 322        437       496       447       482       480       433       515  \n",
       " 1255       384       500       509       472       486       508       504  \n",
       " 1180       404       525       509       484       492       477       469  \n",
       " 1038       549       491       530       471       459       484       445  \n",
       " 968        274       486       502       489       487       504       461  \n",
       " 493        520       483       573       481       462       575       450  \n",
       " 1438       348       454       433       486       505       467       505  \n",
       " 262        747       529       500       476       476       568       493  \n",
       " 145        693       534       516       466       487       589       494  \n",
       " 1610       347       491       484       477       453       406       497  \n",
       " 860        790       443       501       473       495       534       463  \n",
       " 1819       441       500       588       479       484       486       497  \n",
       " 1989       639       522       558       474       477       579       504  \n",
       " 1589       457       489       507       486       486       464       500  \n",
       " 49         509       436       500       485       529       529       439  \n",
       " 120        427       540       582       478       480       515       521  \n",
       " 1508       383       498       561       477       476       513       521  \n",
       " 984        613       511       476       470       498       533       519  \n",
       " 837        545       519       521       478       488       560       480  \n",
       " \n",
       " [500 rows x 500 columns],\n",
       " 'X_train':       feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
       " 901        474       526       476       488       511       492       490   \n",
       " 935        494       483       555       487       557       481       515   \n",
       " 455        484       497       483       484       491       474       526   \n",
       " 1744       476       465       474       477       416       474       496   \n",
       " 1230       474       488       522       487       529       481       394   \n",
       " 1937       473       464       526       483       452       485       515   \n",
       " 343        471       446       522       476       499       468       516   \n",
       " 1411       482       475       477       472       516       485       493   \n",
       " 799        483       506       505       486       477       473       457   \n",
       " 1932       488       538       441       488       583       481       454   \n",
       " 1026       483       525       512       493       549       487       511   \n",
       " 111        481       466       596       505       496       486       487   \n",
       " 1100       475       584       522       493       492       481       461   \n",
       " 36         487       477       509       489       468       475       430   \n",
       " 1407       464       461       444       487       501       477       399   \n",
       " 1194       488       523       487       483       508       476       502   \n",
       " 582        484       491       572       479       495       472       504   \n",
       " 1550       474       482       422       477       494       477       493   \n",
       " 1256       486       521       568       487       476       475       493   \n",
       " 891        488       419       536       490       450       469       513   \n",
       " 1614       478       497       458       487       493       478       510   \n",
       " 173        482       492       535       494       521       502       462   \n",
       " 1415       482       503       466       497       553       466       543   \n",
       " 1602       468       487       485       480       516       479       518   \n",
       " 1895       478       446       541       465       435       484       381   \n",
       " 478        485       476       493       482       455       475       492   \n",
       " 513        483       488       504       483       438       484       516   \n",
       " 329        478       495       488       483       436       490       461   \n",
       " 1640       482       450       514       498       512       481       425   \n",
       " 1948       489       533       445       494       538       476       448   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 1796       483       551       570       501       496       485       490   \n",
       " 787        485       538       452       481       473       468       532   \n",
       " 544        476       523       519       487       537       462       444   \n",
       " 366        480       541       503       488       486       466       479   \n",
       " 456        481       476       515       480       537       478       457   \n",
       " 862        481       504       440       487       506       482       458   \n",
       " 358        476       449       499       485       499       473       508   \n",
       " 1952       484       428       531       498       516       481       482   \n",
       " 1619       480       519       467       486       404       478       474   \n",
       " 615        483       434       507       488       510       475       467   \n",
       " 517        473       491       504       476       490       472       521   \n",
       " 975        476       474       566       491       451       486       467   \n",
       " 1448       487       486       495       481       421       481       499   \n",
       " 1539       480       454       452       480       521       482       453   \n",
       " 1960       486       472       493       489       428       477       538   \n",
       " 1571       487       455       584       488       507       475       504   \n",
       " 304        482       478       505       489       482       469       455   \n",
       " 382        483       436       509       490       455       479       501   \n",
       " 748        474       517       542       485       541       479       460   \n",
       " 342        485       473       510       483       564       484       463   \n",
       " 310        491       459       539       481       497       480       452   \n",
       " 1626       476       460       526       489       519       481       491   \n",
       " 1663       497       480       496       481       471       505       513   \n",
       " 1510       479       434       593       475       563       465       444   \n",
       " 546        487       480       527       487       430       473       494   \n",
       " 881        488       435       488       488       604       493       504   \n",
       " 1101       471       534       527       492       474       479       497   \n",
       " 757        481       464       498       492       483       483       406   \n",
       " 1481       472       498       484       492       519       488       440   \n",
       " 1386       480       453       475       488       489       478       512   \n",
       " \n",
       "       feat_007  feat_008  feat_009    ...     feat_490  feat_491  feat_492  \\\n",
       " 901        476       473       488    ...          459       475       460   \n",
       " 935        477       483       487    ...          479       476       485   \n",
       " 455        477       488       477    ...          475       476       493   \n",
       " 1744       476       510       484    ...          438       478       512   \n",
       " 1230       476       479       484    ...          504       472       466   \n",
       " 1937       478       484       483    ...          491       476       515   \n",
       " 343        476       469       484    ...          492       471       482   \n",
       " 1411       475       499       486    ...          497       476       552   \n",
       " 799        476       483       485    ...          490       477       527   \n",
       " 1932       477       510       487    ...          474       477       503   \n",
       " 1026       477       515       479    ...          475       478       468   \n",
       " 111        477       464       472    ...          443       478       436   \n",
       " 1100       476       459       479    ...          520       477       503   \n",
       " 36         476       486       486    ...          480       480       489   \n",
       " 1407       475       507       488    ...          475       477       466   \n",
       " 1194       480       480       488    ...          488       476       519   \n",
       " 582        478       496       483    ...          437       477       516   \n",
       " 1550       478       477       471    ...          476       477       483   \n",
       " 1256       476       506       473    ...          507       473       547   \n",
       " 891        473       479       482    ...          472       477       463   \n",
       " 1614       477       487       471    ...          465       468       519   \n",
       " 173        476       491       473    ...          481       482       497   \n",
       " 1415       478       469       482    ...          492       473       536   \n",
       " 1602       475       485       476    ...          512       480       480   \n",
       " 1895       478       443       488    ...          527       479       453   \n",
       " 478        475       519       470    ...          449       480       490   \n",
       " 513        477       478       482    ...          481       480       459   \n",
       " 329        478       463       484    ...          480       474       474   \n",
       " 1640       478       521       465    ...          483       477       470   \n",
       " 1948       476       484       491    ...          498       487       489   \n",
       " ...        ...       ...       ...    ...          ...       ...       ...   \n",
       " 1796       475       481       488    ...          463       481       463   \n",
       " 787        480       498       487    ...          532       476       507   \n",
       " 544        477       468       471    ...          468       480       437   \n",
       " 366        475       463       479    ...          486       480       477   \n",
       " 456        476       478       483    ...          467       477       479   \n",
       " 862        475       484       479    ...          477       474       488   \n",
       " 358        474       452       489    ...          468       482       546   \n",
       " 1952       478       480       488    ...          493       478       500   \n",
       " 1619       475       470       477    ...          507       481       536   \n",
       " 615        476       485       483    ...          466       478       520   \n",
       " 517        476       506       483    ...          435       476       492   \n",
       " 975        479       489       478    ...          492       474       506   \n",
       " 1448       478       489       482    ...          486       477       511   \n",
       " 1539       477       483       481    ...          444       479       484   \n",
       " 1960       476       483       485    ...          467       477       473   \n",
       " 1571       478       482       479    ...          479       479       494   \n",
       " 304        479       502       477    ...          487       477       471   \n",
       " 382        477       522       474    ...          444       485       475   \n",
       " 748        477       478       474    ...          470       483       468   \n",
       " 342        476       518       476    ...          499       479       503   \n",
       " 310        478       463       487    ...          469       481       519   \n",
       " 1626       477       492       479    ...          513       479       497   \n",
       " 1663       477       494       483    ...          465       481       536   \n",
       " 1510       475       487       480    ...          492       475       494   \n",
       " 546        476       498       477    ...          468       474       476   \n",
       " 881        479       494       480    ...          488       475       444   \n",
       " 1101       478       495       472    ...          517       475       492   \n",
       " 757        478       502       486    ...          441       483       487   \n",
       " 1481       477       479       466    ...          516       485       497   \n",
       " 1386       480       489       479    ...          465       480       519   \n",
       " \n",
       "       feat_493  feat_494  feat_495  feat_496  feat_497  feat_498  feat_499  \n",
       " 901        348       456       552       491       473       495       484  \n",
       " 935        567       505       456       477       471       505       490  \n",
       " 455        507       507       502       469       481       543       491  \n",
       " 1744       438       460       463       485       476       447       482  \n",
       " 1230       442       466       487       475       482       588       504  \n",
       " 1937       556       431       526       476       500       471       508  \n",
       " 343        353       445       523       473       480       489       449  \n",
       " 1411       439       488       481       482       470       559       519  \n",
       " 799        353       507       485       484       458       588       515  \n",
       " 1932       584       475       467       478       485       508       481  \n",
       " 1026       493       496       511       479       480       511       455  \n",
       " 111        364       481       554       480       477       492       443  \n",
       " 1100       417       463       500       475       488       447       522  \n",
       " 36         571       556       540       475       489       546       467  \n",
       " 1407       291       466       529       483       480       457       484  \n",
       " 1194       510       487       511       482       465       552       506  \n",
       " 582        553       505       547       485       481       558       470  \n",
       " 1550       471       415       516       483       501       451       509  \n",
       " 1256       428       488       470       484       493       469       514  \n",
       " 891        614       539       493       472       490       497       475  \n",
       " 1614       551       456       524       485       504       495       472  \n",
       " 173        481       526       490       481       493       482       494  \n",
       " 1415       575       511       532       473       477       520       492  \n",
       " 1602       596       482       549       485       495       451       476  \n",
       " 1895       580       467       497       481       478       525       467  \n",
       " 478        496       479       538       478       483       573       501  \n",
       " 513        703       478       532       473       466       503       412  \n",
       " 329        531       494       553       467       476       522       505  \n",
       " 1640       528       482       520       486       470       501       518  \n",
       " 1948       392       486       516       481       499       491       535  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 1796       393       562       537       475       483       457       460  \n",
       " 787        549       479       468       481       494       496       476  \n",
       " 544        667       527       550       473       451       473       501  \n",
       " 366        292       541       525       480       478       524       464  \n",
       " 456        567       440       473       474       494       496       509  \n",
       " 862        381       491       575       464       468       481       501  \n",
       " 358        539       509       564       480       494       497       526  \n",
       " 1952       452       550       473       474       483       535       508  \n",
       " 1619       514       500       521       472       490       495       517  \n",
       " 615        277       486       523       479       476       516       486  \n",
       " 517        561       508       439       471       484       528       426  \n",
       " 975        752       473       522       474       458       480       490  \n",
       " 1448       245       522       480       483       493       421       488  \n",
       " 1539       470       484       477       483       500       478       515  \n",
       " 1960       587       534       481       480       492       563       474  \n",
       " 1571       533       480       526       479       473       495       462  \n",
       " 304        342       516       498       476       490       517       470  \n",
       " 382        285       510       497       477       463       511       500  \n",
       " 748        340       507       520       475       480       537       507  \n",
       " 342        560       524       518       477       497       525       541  \n",
       " 310        186       534       523       468       484       567       467  \n",
       " 1626       682       549       492       478       455       492       499  \n",
       " 1663       357       436       535       483       473       601       502  \n",
       " 1510       272       490       575       475       480       441       491  \n",
       " 546        562       519       535       470       510       573       451  \n",
       " 881        249       468       502       478       490       532       488  \n",
       " 1101       360       505       530       473       496       446       542  \n",
       " 757        566       470       510       478       481       457       509  \n",
       " 1481       611       453       490       476       487       528       523  \n",
       " 1386       544       513       498       472       493       478       446  \n",
       " \n",
       " [1500 rows x 500 columns],\n",
       " 'y_test': 1938    1\n",
       " 427     1\n",
       " 548    -1\n",
       " 1715   -1\n",
       " 390     1\n",
       " 930    -1\n",
       " 1107   -1\n",
       " 1605   -1\n",
       " 110    -1\n",
       " 1296   -1\n",
       " 70     -1\n",
       " 1201    1\n",
       " 689    -1\n",
       " 38     -1\n",
       " 810    -1\n",
       " 407     1\n",
       " 1821   -1\n",
       " 1794    1\n",
       " 230     1\n",
       " 1835   -1\n",
       " 397     1\n",
       " 723    -1\n",
       " 360     1\n",
       " 1775   -1\n",
       " 180     1\n",
       " 589    -1\n",
       " 1561   -1\n",
       " 906    -1\n",
       " 380    -1\n",
       " 1732   -1\n",
       "        ..\n",
       " 617    -1\n",
       " 1224    1\n",
       " 1750    1\n",
       " 1706    1\n",
       " 1655   -1\n",
       " 645     1\n",
       " 124     1\n",
       " 1763   -1\n",
       " 1720    1\n",
       " 1964    1\n",
       " 218     1\n",
       " 322    -1\n",
       " 1255   -1\n",
       " 1180    1\n",
       " 1038    1\n",
       " 968     1\n",
       " 493     1\n",
       " 1438    1\n",
       " 262     1\n",
       " 145    -1\n",
       " 1610   -1\n",
       " 860     1\n",
       " 1819    1\n",
       " 1989    1\n",
       " 1589    1\n",
       " 49     -1\n",
       " 120    -1\n",
       " 1508   -1\n",
       " 984     1\n",
       " 837    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 901     1\n",
       " 935     1\n",
       " 455    -1\n",
       " 1744    1\n",
       " 1230    1\n",
       " 1937   -1\n",
       " 343     1\n",
       " 1411    1\n",
       " 799     1\n",
       " 1932   -1\n",
       " 1026    1\n",
       " 111    -1\n",
       " 1100   -1\n",
       " 36     -1\n",
       " 1407    1\n",
       " 1194   -1\n",
       " 582     1\n",
       " 1550   -1\n",
       " 1256    1\n",
       " 891     1\n",
       " 1614   -1\n",
       " 173    -1\n",
       " 1415    1\n",
       " 1602   -1\n",
       " 1895   -1\n",
       " 478    -1\n",
       " 513     1\n",
       " 329    -1\n",
       " 1640    1\n",
       " 1948    1\n",
       "        ..\n",
       " 1796   -1\n",
       " 787     1\n",
       " 544    -1\n",
       " 366    -1\n",
       " 456     1\n",
       " 862     1\n",
       " 358    -1\n",
       " 1952    1\n",
       " 1619    1\n",
       " 615    -1\n",
       " 517    -1\n",
       " 975    -1\n",
       " 1448    1\n",
       " 1539    1\n",
       " 1960    1\n",
       " 1571   -1\n",
       " 304     1\n",
       " 382    -1\n",
       " 748     1\n",
       " 342    -1\n",
       " 310    -1\n",
       " 1626   -1\n",
       " 1663   -1\n",
       " 1510    1\n",
       " 546    -1\n",
       " 881    -1\n",
       " 1101    1\n",
       " 757     1\n",
       " 1481    1\n",
       " 1386   -1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data_dict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict=make_data_dict(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "         -0.72312012, -0.44707028],\n",
       "        [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "         -0.80232083, -0.83443477],\n",
       "        [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "          0.64969225,  0.75375966],\n",
       "        ..., \n",
       "        [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "          0.96649511,  0.40513161],\n",
       "        [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "         -0.77592059,  0.13397647],\n",
       "        [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "         -0.80232083,  0.36639516]]),\n",
       " 'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "         -0.01031369,  0.05650357],\n",
       "        [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "          1.07209606,  0.44386806],\n",
       "        [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "         -0.85512131, -0.17591513],\n",
       "        ..., \n",
       "        [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "         -1.4095263 ,  0.40513161],\n",
       "        [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "          0.22728845,  0.71502321],\n",
       "        [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "         -1.09272345, -0.09844223]]),\n",
       " 'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "          -0.72312012, -0.44707028],\n",
       "         [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "          -0.80232083, -0.83443477],\n",
       "         [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "           0.64969225,  0.75375966],\n",
       "         ..., \n",
       "         [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "           0.96649511,  0.40513161],\n",
       "         [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "          -0.77592059,  0.13397647],\n",
       "         [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "          -0.80232083,  0.36639516]]),\n",
       "  'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "          -0.01031369,  0.05650357],\n",
       "         [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "           1.07209606,  0.44386806],\n",
       "         [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "          -0.85512131, -0.17591513],\n",
       "         ..., \n",
       "         [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "          -1.4095263 ,  0.40513161],\n",
       "         [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "           0.22728845,  0.71502321],\n",
       "         [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "          -1.09272345, -0.09844223]]),\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "general_transformer(StandardScaler(),data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SS_data_dict=general_transformer(StandardScaler(),data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "        [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "        [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "        ..., \n",
       "        [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "        [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "        [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       " 'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "        [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "        [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "        ..., \n",
       "        [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "        [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "        [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       " 'data_dict': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "         [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "         [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "         ..., \n",
       "         [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "         [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "         [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "  'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "         [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "         [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "         ..., \n",
       "         [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "         [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "         [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "  'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "           -0.72312012, -0.44707028],\n",
       "          [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "           -0.80232083, -0.83443477],\n",
       "          [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "            0.64969225,  0.75375966],\n",
       "          ..., \n",
       "          [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "            0.96649511,  0.40513161],\n",
       "          [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "           -0.77592059,  0.13397647],\n",
       "          [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "           -0.80232083,  0.36639516]]),\n",
       "   'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "           -0.01031369,  0.05650357],\n",
       "          [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "            1.07209606,  0.44386806],\n",
       "          [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "           -0.85512131, -0.17591513],\n",
       "          ..., \n",
       "          [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "           -1.4095263 ,  0.40513161],\n",
       "          [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "            0.22728845,  0.71502321],\n",
       "          [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "           -1.09272345, -0.09844223]]),\n",
       "   'y_test': 32      1\n",
       "   1180    1\n",
       "   1466   -1\n",
       "   463    -1\n",
       "   1560   -1\n",
       "   1866   -1\n",
       "   925     1\n",
       "   856    -1\n",
       "   1614   -1\n",
       "   949     1\n",
       "   402     1\n",
       "   852    -1\n",
       "   8       1\n",
       "   150    -1\n",
       "   1481    1\n",
       "   297    -1\n",
       "   1580    1\n",
       "   1431   -1\n",
       "   1124   -1\n",
       "   726    -1\n",
       "   1857   -1\n",
       "   1803   -1\n",
       "   1382    1\n",
       "   692     1\n",
       "   469     1\n",
       "   293     1\n",
       "   729     1\n",
       "   427     1\n",
       "   356     1\n",
       "   1271    1\n",
       "          ..\n",
       "   394     1\n",
       "   327     1\n",
       "   1350   -1\n",
       "   98     -1\n",
       "   1639    1\n",
       "   1816   -1\n",
       "   164     1\n",
       "   1662   -1\n",
       "   229     1\n",
       "   946     1\n",
       "   465     1\n",
       "   975    -1\n",
       "   366    -1\n",
       "   67      1\n",
       "   1922    1\n",
       "   616     1\n",
       "   1806   -1\n",
       "   213     1\n",
       "   1210    1\n",
       "   970    -1\n",
       "   987    -1\n",
       "   1772    1\n",
       "   13     -1\n",
       "   1294    1\n",
       "   618     1\n",
       "   1464   -1\n",
       "   1133    1\n",
       "   400     1\n",
       "   1033    1\n",
       "   157    -1\n",
       "   Name: label, dtype: int64,\n",
       "   'y_train': 833     1\n",
       "   263    -1\n",
       "   1961    1\n",
       "   1157   -1\n",
       "   640    -1\n",
       "   214    -1\n",
       "   549     1\n",
       "   614     1\n",
       "   1691   -1\n",
       "   85     -1\n",
       "   414    -1\n",
       "   1895   -1\n",
       "   695    -1\n",
       "   167     1\n",
       "   5       1\n",
       "   1528    1\n",
       "   1176    1\n",
       "   344    -1\n",
       "   1699    1\n",
       "   948     1\n",
       "   1473    1\n",
       "   1470    1\n",
       "   832     1\n",
       "   472    -1\n",
       "   1098   -1\n",
       "   793    -1\n",
       "   981    -1\n",
       "   416     1\n",
       "   1559    1\n",
       "   1818   -1\n",
       "          ..\n",
       "   1689   -1\n",
       "   1147    1\n",
       "   1012   -1\n",
       "   77     -1\n",
       "   1421   -1\n",
       "   595    -1\n",
       "   183    -1\n",
       "   1415    1\n",
       "   1469   -1\n",
       "   1353   -1\n",
       "   1169    1\n",
       "   486    -1\n",
       "   1633   -1\n",
       "   1908   -1\n",
       "   1490   -1\n",
       "   1026    1\n",
       "   937    -1\n",
       "   955    -1\n",
       "   1215   -1\n",
       "   631     1\n",
       "   1549    1\n",
       "   1548   -1\n",
       "   1263    1\n",
       "   447    -1\n",
       "   895     1\n",
       "   1955    1\n",
       "   1583   -1\n",
       "   21      1\n",
       "   1457   -1\n",
       "   1752    1\n",
       "   Name: label, dtype: int64},\n",
       "  'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'transformer': SelectKBest(k=5, score_func=<function f_classif at 0x116f989b0>),\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "general_transformer(SelectKBest(k=5),SS_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KB_data_dict=general_transformer(SelectKBest(k=5),SS_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "        [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "        [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "        ..., \n",
       "        [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "        [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "        [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       " 'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "        [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "        [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "        ..., \n",
       "        [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "        [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "        [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       " 'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "         [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "         [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "         ..., \n",
       "         [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "         [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "         [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "  'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "         [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "         [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "         ..., \n",
       "         [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "         [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "         [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "  'data_dict': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "          [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "          [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "          ..., \n",
       "          [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "          [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "          [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "   'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "          [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "          [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "          ..., \n",
       "          [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "          [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "          [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "   'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "            -0.72312012, -0.44707028],\n",
       "           [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "            -0.80232083, -0.83443477],\n",
       "           [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "             0.64969225,  0.75375966],\n",
       "           ..., \n",
       "           [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "             0.96649511,  0.40513161],\n",
       "           [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "            -0.77592059,  0.13397647],\n",
       "           [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "            -0.80232083,  0.36639516]]),\n",
       "    'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "            -0.01031369,  0.05650357],\n",
       "           [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "             1.07209606,  0.44386806],\n",
       "           [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "            -0.85512131, -0.17591513],\n",
       "           ..., \n",
       "           [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "            -1.4095263 ,  0.40513161],\n",
       "           [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "             0.22728845,  0.71502321],\n",
       "           [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "            -1.09272345, -0.09844223]]),\n",
       "    'y_test': 32      1\n",
       "    1180    1\n",
       "    1466   -1\n",
       "    463    -1\n",
       "    1560   -1\n",
       "    1866   -1\n",
       "    925     1\n",
       "    856    -1\n",
       "    1614   -1\n",
       "    949     1\n",
       "    402     1\n",
       "    852    -1\n",
       "    8       1\n",
       "    150    -1\n",
       "    1481    1\n",
       "    297    -1\n",
       "    1580    1\n",
       "    1431   -1\n",
       "    1124   -1\n",
       "    726    -1\n",
       "    1857   -1\n",
       "    1803   -1\n",
       "    1382    1\n",
       "    692     1\n",
       "    469     1\n",
       "    293     1\n",
       "    729     1\n",
       "    427     1\n",
       "    356     1\n",
       "    1271    1\n",
       "           ..\n",
       "    394     1\n",
       "    327     1\n",
       "    1350   -1\n",
       "    98     -1\n",
       "    1639    1\n",
       "    1816   -1\n",
       "    164     1\n",
       "    1662   -1\n",
       "    229     1\n",
       "    946     1\n",
       "    465     1\n",
       "    975    -1\n",
       "    366    -1\n",
       "    67      1\n",
       "    1922    1\n",
       "    616     1\n",
       "    1806   -1\n",
       "    213     1\n",
       "    1210    1\n",
       "    970    -1\n",
       "    987    -1\n",
       "    1772    1\n",
       "    13     -1\n",
       "    1294    1\n",
       "    618     1\n",
       "    1464   -1\n",
       "    1133    1\n",
       "    400     1\n",
       "    1033    1\n",
       "    157    -1\n",
       "    Name: label, dtype: int64,\n",
       "    'y_train': 833     1\n",
       "    263    -1\n",
       "    1961    1\n",
       "    1157   -1\n",
       "    640    -1\n",
       "    214    -1\n",
       "    549     1\n",
       "    614     1\n",
       "    1691   -1\n",
       "    85     -1\n",
       "    414    -1\n",
       "    1895   -1\n",
       "    695    -1\n",
       "    167     1\n",
       "    5       1\n",
       "    1528    1\n",
       "    1176    1\n",
       "    344    -1\n",
       "    1699    1\n",
       "    948     1\n",
       "    1473    1\n",
       "    1470    1\n",
       "    832     1\n",
       "    472    -1\n",
       "    1098   -1\n",
       "    793    -1\n",
       "    981    -1\n",
       "    416     1\n",
       "    1559    1\n",
       "    1818   -1\n",
       "           ..\n",
       "    1689   -1\n",
       "    1147    1\n",
       "    1012   -1\n",
       "    77     -1\n",
       "    1421   -1\n",
       "    595    -1\n",
       "    183    -1\n",
       "    1415    1\n",
       "    1469   -1\n",
       "    1353   -1\n",
       "    1169    1\n",
       "    486    -1\n",
       "    1633   -1\n",
       "    1908   -1\n",
       "    1490   -1\n",
       "    1026    1\n",
       "    937    -1\n",
       "    955    -1\n",
       "    1215   -1\n",
       "    631     1\n",
       "    1549    1\n",
       "    1548   -1\n",
       "    1263    1\n",
       "    447    -1\n",
       "    895     1\n",
       "    1955    1\n",
       "    1583   -1\n",
       "    21      1\n",
       "    1457   -1\n",
       "    1752    1\n",
       "    Name: label, dtype: int64},\n",
       "   'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "   'y_test': 32      1\n",
       "   1180    1\n",
       "   1466   -1\n",
       "   463    -1\n",
       "   1560   -1\n",
       "   1866   -1\n",
       "   925     1\n",
       "   856    -1\n",
       "   1614   -1\n",
       "   949     1\n",
       "   402     1\n",
       "   852    -1\n",
       "   8       1\n",
       "   150    -1\n",
       "   1481    1\n",
       "   297    -1\n",
       "   1580    1\n",
       "   1431   -1\n",
       "   1124   -1\n",
       "   726    -1\n",
       "   1857   -1\n",
       "   1803   -1\n",
       "   1382    1\n",
       "   692     1\n",
       "   469     1\n",
       "   293     1\n",
       "   729     1\n",
       "   427     1\n",
       "   356     1\n",
       "   1271    1\n",
       "          ..\n",
       "   394     1\n",
       "   327     1\n",
       "   1350   -1\n",
       "   98     -1\n",
       "   1639    1\n",
       "   1816   -1\n",
       "   164     1\n",
       "   1662   -1\n",
       "   229     1\n",
       "   946     1\n",
       "   465     1\n",
       "   975    -1\n",
       "   366    -1\n",
       "   67      1\n",
       "   1922    1\n",
       "   616     1\n",
       "   1806   -1\n",
       "   213     1\n",
       "   1210    1\n",
       "   970    -1\n",
       "   987    -1\n",
       "   1772    1\n",
       "   13     -1\n",
       "   1294    1\n",
       "   618     1\n",
       "   1464   -1\n",
       "   1133    1\n",
       "   400     1\n",
       "   1033    1\n",
       "   157    -1\n",
       "   Name: label, dtype: int64,\n",
       "   'y_train': 833     1\n",
       "   263    -1\n",
       "   1961    1\n",
       "   1157   -1\n",
       "   640    -1\n",
       "   214    -1\n",
       "   549     1\n",
       "   614     1\n",
       "   1691   -1\n",
       "   85     -1\n",
       "   414    -1\n",
       "   1895   -1\n",
       "   695    -1\n",
       "   167     1\n",
       "   5       1\n",
       "   1528    1\n",
       "   1176    1\n",
       "   344    -1\n",
       "   1699    1\n",
       "   948     1\n",
       "   1473    1\n",
       "   1470    1\n",
       "   832     1\n",
       "   472    -1\n",
       "   1098   -1\n",
       "   793    -1\n",
       "   981    -1\n",
       "   416     1\n",
       "   1559    1\n",
       "   1818   -1\n",
       "          ..\n",
       "   1689   -1\n",
       "   1147    1\n",
       "   1012   -1\n",
       "   77     -1\n",
       "   1421   -1\n",
       "   595    -1\n",
       "   183    -1\n",
       "   1415    1\n",
       "   1469   -1\n",
       "   1353   -1\n",
       "   1169    1\n",
       "   486    -1\n",
       "   1633   -1\n",
       "   1908   -1\n",
       "   1490   -1\n",
       "   1026    1\n",
       "   937    -1\n",
       "   955    -1\n",
       "   1215   -1\n",
       "   631     1\n",
       "   1549    1\n",
       "   1548   -1\n",
       "   1263    1\n",
       "   447    -1\n",
       "   895     1\n",
       "   1955    1\n",
       "   1583   -1\n",
       "   21      1\n",
       "   1457   -1\n",
       "   1752    1\n",
       "   Name: label, dtype: int64},\n",
       "  'test_score': 0.624,\n",
       "  'train_score': 0.61466666666666669,\n",
       "  'transformer': SelectKBest(k=5, score_func=<function f_classif at 0x116f989b0>),\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       " 'test_score': 0.624,\n",
       " 'train_score': 0.61466666666666669,\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "general_model(LogisticRegression(),KB_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_data_dict=general_model(LogisticRegression(),KB_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "        [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "        [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "        ..., \n",
       "        [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "        [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "        [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       " 'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "        [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "        [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "        ..., \n",
       "        [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "        [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "        [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       " 'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "         [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "         [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "         ..., \n",
       "         [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "         [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "         [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "  'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "         [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "         [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "         ..., \n",
       "         [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "         [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "         [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "  'data_dict': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "          [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "          [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "          ..., \n",
       "          [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "          [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "          [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "   'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "          [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "          [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "          ..., \n",
       "          [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "          [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "          [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "   'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "            -0.72312012, -0.44707028],\n",
       "           [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "            -0.80232083, -0.83443477],\n",
       "           [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "             0.64969225,  0.75375966],\n",
       "           ..., \n",
       "           [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "             0.96649511,  0.40513161],\n",
       "           [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "            -0.77592059,  0.13397647],\n",
       "           [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "            -0.80232083,  0.36639516]]),\n",
       "    'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "            -0.01031369,  0.05650357],\n",
       "           [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "             1.07209606,  0.44386806],\n",
       "           [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "            -0.85512131, -0.17591513],\n",
       "           ..., \n",
       "           [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "            -1.4095263 ,  0.40513161],\n",
       "           [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "             0.22728845,  0.71502321],\n",
       "           [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "            -1.09272345, -0.09844223]]),\n",
       "    'y_test': 32      1\n",
       "    1180    1\n",
       "    1466   -1\n",
       "    463    -1\n",
       "    1560   -1\n",
       "    1866   -1\n",
       "    925     1\n",
       "    856    -1\n",
       "    1614   -1\n",
       "    949     1\n",
       "    402     1\n",
       "    852    -1\n",
       "    8       1\n",
       "    150    -1\n",
       "    1481    1\n",
       "    297    -1\n",
       "    1580    1\n",
       "    1431   -1\n",
       "    1124   -1\n",
       "    726    -1\n",
       "    1857   -1\n",
       "    1803   -1\n",
       "    1382    1\n",
       "    692     1\n",
       "    469     1\n",
       "    293     1\n",
       "    729     1\n",
       "    427     1\n",
       "    356     1\n",
       "    1271    1\n",
       "           ..\n",
       "    394     1\n",
       "    327     1\n",
       "    1350   -1\n",
       "    98     -1\n",
       "    1639    1\n",
       "    1816   -1\n",
       "    164     1\n",
       "    1662   -1\n",
       "    229     1\n",
       "    946     1\n",
       "    465     1\n",
       "    975    -1\n",
       "    366    -1\n",
       "    67      1\n",
       "    1922    1\n",
       "    616     1\n",
       "    1806   -1\n",
       "    213     1\n",
       "    1210    1\n",
       "    970    -1\n",
       "    987    -1\n",
       "    1772    1\n",
       "    13     -1\n",
       "    1294    1\n",
       "    618     1\n",
       "    1464   -1\n",
       "    1133    1\n",
       "    400     1\n",
       "    1033    1\n",
       "    157    -1\n",
       "    Name: label, dtype: int64,\n",
       "    'y_train': 833     1\n",
       "    263    -1\n",
       "    1961    1\n",
       "    1157   -1\n",
       "    640    -1\n",
       "    214    -1\n",
       "    549     1\n",
       "    614     1\n",
       "    1691   -1\n",
       "    85     -1\n",
       "    414    -1\n",
       "    1895   -1\n",
       "    695    -1\n",
       "    167     1\n",
       "    5       1\n",
       "    1528    1\n",
       "    1176    1\n",
       "    344    -1\n",
       "    1699    1\n",
       "    948     1\n",
       "    1473    1\n",
       "    1470    1\n",
       "    832     1\n",
       "    472    -1\n",
       "    1098   -1\n",
       "    793    -1\n",
       "    981    -1\n",
       "    416     1\n",
       "    1559    1\n",
       "    1818   -1\n",
       "           ..\n",
       "    1689   -1\n",
       "    1147    1\n",
       "    1012   -1\n",
       "    77     -1\n",
       "    1421   -1\n",
       "    595    -1\n",
       "    183    -1\n",
       "    1415    1\n",
       "    1469   -1\n",
       "    1353   -1\n",
       "    1169    1\n",
       "    486    -1\n",
       "    1633   -1\n",
       "    1908   -1\n",
       "    1490   -1\n",
       "    1026    1\n",
       "    937    -1\n",
       "    955    -1\n",
       "    1215   -1\n",
       "    631     1\n",
       "    1549    1\n",
       "    1548   -1\n",
       "    1263    1\n",
       "    447    -1\n",
       "    895     1\n",
       "    1955    1\n",
       "    1583   -1\n",
       "    21      1\n",
       "    1457   -1\n",
       "    1752    1\n",
       "    Name: label, dtype: int64},\n",
       "   'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "   'y_test': 32      1\n",
       "   1180    1\n",
       "   1466   -1\n",
       "   463    -1\n",
       "   1560   -1\n",
       "   1866   -1\n",
       "   925     1\n",
       "   856    -1\n",
       "   1614   -1\n",
       "   949     1\n",
       "   402     1\n",
       "   852    -1\n",
       "   8       1\n",
       "   150    -1\n",
       "   1481    1\n",
       "   297    -1\n",
       "   1580    1\n",
       "   1431   -1\n",
       "   1124   -1\n",
       "   726    -1\n",
       "   1857   -1\n",
       "   1803   -1\n",
       "   1382    1\n",
       "   692     1\n",
       "   469     1\n",
       "   293     1\n",
       "   729     1\n",
       "   427     1\n",
       "   356     1\n",
       "   1271    1\n",
       "          ..\n",
       "   394     1\n",
       "   327     1\n",
       "   1350   -1\n",
       "   98     -1\n",
       "   1639    1\n",
       "   1816   -1\n",
       "   164     1\n",
       "   1662   -1\n",
       "   229     1\n",
       "   946     1\n",
       "   465     1\n",
       "   975    -1\n",
       "   366    -1\n",
       "   67      1\n",
       "   1922    1\n",
       "   616     1\n",
       "   1806   -1\n",
       "   213     1\n",
       "   1210    1\n",
       "   970    -1\n",
       "   987    -1\n",
       "   1772    1\n",
       "   13     -1\n",
       "   1294    1\n",
       "   618     1\n",
       "   1464   -1\n",
       "   1133    1\n",
       "   400     1\n",
       "   1033    1\n",
       "   157    -1\n",
       "   Name: label, dtype: int64,\n",
       "   'y_train': 833     1\n",
       "   263    -1\n",
       "   1961    1\n",
       "   1157   -1\n",
       "   640    -1\n",
       "   214    -1\n",
       "   549     1\n",
       "   614     1\n",
       "   1691   -1\n",
       "   85     -1\n",
       "   414    -1\n",
       "   1895   -1\n",
       "   695    -1\n",
       "   167     1\n",
       "   5       1\n",
       "   1528    1\n",
       "   1176    1\n",
       "   344    -1\n",
       "   1699    1\n",
       "   948     1\n",
       "   1473    1\n",
       "   1470    1\n",
       "   832     1\n",
       "   472    -1\n",
       "   1098   -1\n",
       "   793    -1\n",
       "   981    -1\n",
       "   416     1\n",
       "   1559    1\n",
       "   1818   -1\n",
       "          ..\n",
       "   1689   -1\n",
       "   1147    1\n",
       "   1012   -1\n",
       "   77     -1\n",
       "   1421   -1\n",
       "   595    -1\n",
       "   183    -1\n",
       "   1415    1\n",
       "   1469   -1\n",
       "   1353   -1\n",
       "   1169    1\n",
       "   486    -1\n",
       "   1633   -1\n",
       "   1908   -1\n",
       "   1490   -1\n",
       "   1026    1\n",
       "   937    -1\n",
       "   955    -1\n",
       "   1215   -1\n",
       "   631     1\n",
       "   1549    1\n",
       "   1548   -1\n",
       "   1263    1\n",
       "   447    -1\n",
       "   895     1\n",
       "   1955    1\n",
       "   1583   -1\n",
       "   21      1\n",
       "   1457   -1\n",
       "   1752    1\n",
       "   Name: label, dtype: int64},\n",
       "  'test_score': 0.68200000000000005,\n",
       "  'train_score': 0.77533333333333332,\n",
       "  'transformer': SelectKBest(k=5, score_func=<function f_classif at 0x116f989b0>),\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'model': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       " 'test_score': 0.68200000000000005,\n",
       " 'train_score': 0.77533333333333332,\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "general_model(KNeighborsClassifier(), KB_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KNN_data_dict=general_model(KNeighborsClassifier(), KB_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "        [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "        [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "        ..., \n",
       "        [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "        [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "        [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       " 'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "        [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "        [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "        ..., \n",
       "        [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "        [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "        [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       " 'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "         [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "         [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "         ..., \n",
       "         [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "         [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "         [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "  'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "         [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "         [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "         ..., \n",
       "         [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "         [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "         [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "  'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "          [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "          [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "          ..., \n",
       "          [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "          [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "          [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "   'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "          [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "          [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "          ..., \n",
       "          [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "          [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "          [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "   'data_dict': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "           [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "           [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "           ..., \n",
       "           [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "           [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "           [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "    'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "           [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "           [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "           ..., \n",
       "           [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "           [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "           [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "    'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "             -0.72312012, -0.44707028],\n",
       "            [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "             -0.80232083, -0.83443477],\n",
       "            [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "              0.64969225,  0.75375966],\n",
       "            ..., \n",
       "            [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "              0.96649511,  0.40513161],\n",
       "            [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "             -0.77592059,  0.13397647],\n",
       "            [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "             -0.80232083,  0.36639516]]),\n",
       "     'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "             -0.01031369,  0.05650357],\n",
       "            [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "              1.07209606,  0.44386806],\n",
       "            [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "             -0.85512131, -0.17591513],\n",
       "            ..., \n",
       "            [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "             -1.4095263 ,  0.40513161],\n",
       "            [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "              0.22728845,  0.71502321],\n",
       "            [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "             -1.09272345, -0.09844223]]),\n",
       "     'y_test': 32      1\n",
       "     1180    1\n",
       "     1466   -1\n",
       "     463    -1\n",
       "     1560   -1\n",
       "     1866   -1\n",
       "     925     1\n",
       "     856    -1\n",
       "     1614   -1\n",
       "     949     1\n",
       "     402     1\n",
       "     852    -1\n",
       "     8       1\n",
       "     150    -1\n",
       "     1481    1\n",
       "     297    -1\n",
       "     1580    1\n",
       "     1431   -1\n",
       "     1124   -1\n",
       "     726    -1\n",
       "     1857   -1\n",
       "     1803   -1\n",
       "     1382    1\n",
       "     692     1\n",
       "     469     1\n",
       "     293     1\n",
       "     729     1\n",
       "     427     1\n",
       "     356     1\n",
       "     1271    1\n",
       "            ..\n",
       "     394     1\n",
       "     327     1\n",
       "     1350   -1\n",
       "     98     -1\n",
       "     1639    1\n",
       "     1816   -1\n",
       "     164     1\n",
       "     1662   -1\n",
       "     229     1\n",
       "     946     1\n",
       "     465     1\n",
       "     975    -1\n",
       "     366    -1\n",
       "     67      1\n",
       "     1922    1\n",
       "     616     1\n",
       "     1806   -1\n",
       "     213     1\n",
       "     1210    1\n",
       "     970    -1\n",
       "     987    -1\n",
       "     1772    1\n",
       "     13     -1\n",
       "     1294    1\n",
       "     618     1\n",
       "     1464   -1\n",
       "     1133    1\n",
       "     400     1\n",
       "     1033    1\n",
       "     157    -1\n",
       "     Name: label, dtype: int64,\n",
       "     'y_train': 833     1\n",
       "     263    -1\n",
       "     1961    1\n",
       "     1157   -1\n",
       "     640    -1\n",
       "     214    -1\n",
       "     549     1\n",
       "     614     1\n",
       "     1691   -1\n",
       "     85     -1\n",
       "     414    -1\n",
       "     1895   -1\n",
       "     695    -1\n",
       "     167     1\n",
       "     5       1\n",
       "     1528    1\n",
       "     1176    1\n",
       "     344    -1\n",
       "     1699    1\n",
       "     948     1\n",
       "     1473    1\n",
       "     1470    1\n",
       "     832     1\n",
       "     472    -1\n",
       "     1098   -1\n",
       "     793    -1\n",
       "     981    -1\n",
       "     416     1\n",
       "     1559    1\n",
       "     1818   -1\n",
       "            ..\n",
       "     1689   -1\n",
       "     1147    1\n",
       "     1012   -1\n",
       "     77     -1\n",
       "     1421   -1\n",
       "     595    -1\n",
       "     183    -1\n",
       "     1415    1\n",
       "     1469   -1\n",
       "     1353   -1\n",
       "     1169    1\n",
       "     486    -1\n",
       "     1633   -1\n",
       "     1908   -1\n",
       "     1490   -1\n",
       "     1026    1\n",
       "     937    -1\n",
       "     955    -1\n",
       "     1215   -1\n",
       "     631     1\n",
       "     1549    1\n",
       "     1548   -1\n",
       "     1263    1\n",
       "     447    -1\n",
       "     895     1\n",
       "     1955    1\n",
       "     1583   -1\n",
       "     21      1\n",
       "     1457   -1\n",
       "     1752    1\n",
       "     Name: label, dtype: int64},\n",
       "    'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "    'y_test': 32      1\n",
       "    1180    1\n",
       "    1466   -1\n",
       "    463    -1\n",
       "    1560   -1\n",
       "    1866   -1\n",
       "    925     1\n",
       "    856    -1\n",
       "    1614   -1\n",
       "    949     1\n",
       "    402     1\n",
       "    852    -1\n",
       "    8       1\n",
       "    150    -1\n",
       "    1481    1\n",
       "    297    -1\n",
       "    1580    1\n",
       "    1431   -1\n",
       "    1124   -1\n",
       "    726    -1\n",
       "    1857   -1\n",
       "    1803   -1\n",
       "    1382    1\n",
       "    692     1\n",
       "    469     1\n",
       "    293     1\n",
       "    729     1\n",
       "    427     1\n",
       "    356     1\n",
       "    1271    1\n",
       "           ..\n",
       "    394     1\n",
       "    327     1\n",
       "    1350   -1\n",
       "    98     -1\n",
       "    1639    1\n",
       "    1816   -1\n",
       "    164     1\n",
       "    1662   -1\n",
       "    229     1\n",
       "    946     1\n",
       "    465     1\n",
       "    975    -1\n",
       "    366    -1\n",
       "    67      1\n",
       "    1922    1\n",
       "    616     1\n",
       "    1806   -1\n",
       "    213     1\n",
       "    1210    1\n",
       "    970    -1\n",
       "    987    -1\n",
       "    1772    1\n",
       "    13     -1\n",
       "    1294    1\n",
       "    618     1\n",
       "    1464   -1\n",
       "    1133    1\n",
       "    400     1\n",
       "    1033    1\n",
       "    157    -1\n",
       "    Name: label, dtype: int64,\n",
       "    'y_train': 833     1\n",
       "    263    -1\n",
       "    1961    1\n",
       "    1157   -1\n",
       "    640    -1\n",
       "    214    -1\n",
       "    549     1\n",
       "    614     1\n",
       "    1691   -1\n",
       "    85     -1\n",
       "    414    -1\n",
       "    1895   -1\n",
       "    695    -1\n",
       "    167     1\n",
       "    5       1\n",
       "    1528    1\n",
       "    1176    1\n",
       "    344    -1\n",
       "    1699    1\n",
       "    948     1\n",
       "    1473    1\n",
       "    1470    1\n",
       "    832     1\n",
       "    472    -1\n",
       "    1098   -1\n",
       "    793    -1\n",
       "    981    -1\n",
       "    416     1\n",
       "    1559    1\n",
       "    1818   -1\n",
       "           ..\n",
       "    1689   -1\n",
       "    1147    1\n",
       "    1012   -1\n",
       "    77     -1\n",
       "    1421   -1\n",
       "    595    -1\n",
       "    183    -1\n",
       "    1415    1\n",
       "    1469   -1\n",
       "    1353   -1\n",
       "    1169    1\n",
       "    486    -1\n",
       "    1633   -1\n",
       "    1908   -1\n",
       "    1490   -1\n",
       "    1026    1\n",
       "    937    -1\n",
       "    955    -1\n",
       "    1215   -1\n",
       "    631     1\n",
       "    1549    1\n",
       "    1548   -1\n",
       "    1263    1\n",
       "    447    -1\n",
       "    895     1\n",
       "    1955    1\n",
       "    1583   -1\n",
       "    21      1\n",
       "    1457   -1\n",
       "    1752    1\n",
       "    Name: label, dtype: int64},\n",
       "   'test_score': 0.68200000000000005,\n",
       "   'train_score': 0.77533333333333332,\n",
       "   'transformer': SelectKBest(k=5, score_func=<function f_classif at 0x116f989b0>),\n",
       "   'y_test': 32      1\n",
       "   1180    1\n",
       "   1466   -1\n",
       "   463    -1\n",
       "   1560   -1\n",
       "   1866   -1\n",
       "   925     1\n",
       "   856    -1\n",
       "   1614   -1\n",
       "   949     1\n",
       "   402     1\n",
       "   852    -1\n",
       "   8       1\n",
       "   150    -1\n",
       "   1481    1\n",
       "   297    -1\n",
       "   1580    1\n",
       "   1431   -1\n",
       "   1124   -1\n",
       "   726    -1\n",
       "   1857   -1\n",
       "   1803   -1\n",
       "   1382    1\n",
       "   692     1\n",
       "   469     1\n",
       "   293     1\n",
       "   729     1\n",
       "   427     1\n",
       "   356     1\n",
       "   1271    1\n",
       "          ..\n",
       "   394     1\n",
       "   327     1\n",
       "   1350   -1\n",
       "   98     -1\n",
       "   1639    1\n",
       "   1816   -1\n",
       "   164     1\n",
       "   1662   -1\n",
       "   229     1\n",
       "   946     1\n",
       "   465     1\n",
       "   975    -1\n",
       "   366    -1\n",
       "   67      1\n",
       "   1922    1\n",
       "   616     1\n",
       "   1806   -1\n",
       "   213     1\n",
       "   1210    1\n",
       "   970    -1\n",
       "   987    -1\n",
       "   1772    1\n",
       "   13     -1\n",
       "   1294    1\n",
       "   618     1\n",
       "   1464   -1\n",
       "   1133    1\n",
       "   400     1\n",
       "   1033    1\n",
       "   157    -1\n",
       "   Name: label, dtype: int64,\n",
       "   'y_train': 833     1\n",
       "   263    -1\n",
       "   1961    1\n",
       "   1157   -1\n",
       "   640    -1\n",
       "   214    -1\n",
       "   549     1\n",
       "   614     1\n",
       "   1691   -1\n",
       "   85     -1\n",
       "   414    -1\n",
       "   1895   -1\n",
       "   695    -1\n",
       "   167     1\n",
       "   5       1\n",
       "   1528    1\n",
       "   1176    1\n",
       "   344    -1\n",
       "   1699    1\n",
       "   948     1\n",
       "   1473    1\n",
       "   1470    1\n",
       "   832     1\n",
       "   472    -1\n",
       "   1098   -1\n",
       "   793    -1\n",
       "   981    -1\n",
       "   416     1\n",
       "   1559    1\n",
       "   1818   -1\n",
       "          ..\n",
       "   1689   -1\n",
       "   1147    1\n",
       "   1012   -1\n",
       "   77     -1\n",
       "   1421   -1\n",
       "   595    -1\n",
       "   183    -1\n",
       "   1415    1\n",
       "   1469   -1\n",
       "   1353   -1\n",
       "   1169    1\n",
       "   486    -1\n",
       "   1633   -1\n",
       "   1908   -1\n",
       "   1490   -1\n",
       "   1026    1\n",
       "   937    -1\n",
       "   955    -1\n",
       "   1215   -1\n",
       "   631     1\n",
       "   1549    1\n",
       "   1548   -1\n",
       "   1263    1\n",
       "   447    -1\n",
       "   895     1\n",
       "   1955    1\n",
       "   1583   -1\n",
       "   21      1\n",
       "   1457   -1\n",
       "   1752    1\n",
       "   Name: label, dtype: int64},\n",
       "  'model': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False),\n",
       "  'test_score': 0.62,\n",
       "  'train_score': 0.61533333333333329,\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'model': GridSearchCV(cv=None, error_score='raise',\n",
       "        estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0, warm_start=False),\n",
       "        fit_params={}, iid=True, n_jobs=1,\n",
       "        param_grid={'C': [0.01, 0.1, 1, 100.0]}, pre_dispatch='2*n_jobs',\n",
       "        refit=True, return_train_score=True, scoring=None, verbose=0),\n",
       " 'test_score': 0.62,\n",
       " 'train_score': 0.61533333333333329,\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C' : [1E-2, 1E-1, 1, 1E2]    \n",
    "}\n",
    "grid_searchlg = GridSearchCV(LogisticRegression(), param_grid=params)\n",
    "\n",
    "general_model(grid_searchlg, LR_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.61533333333333329, 0.62)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRGS=general_model(grid_searchlg, LR_data_dict)\n",
    "LRGS['train_score'], LRGS['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "        [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "        [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "        ..., \n",
       "        [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "        [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "        [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       " 'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "        [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "        [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "        ..., \n",
       "        [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "        [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "        [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       " 'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "         [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "         [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "         ..., \n",
       "         [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "         [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "         [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "  'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "         [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "         [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "         ..., \n",
       "         [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "         [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "         [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "  'data_dictionary': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "          [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "          [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "          ..., \n",
       "          [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "          [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "          [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "   'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "          [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "          [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "          ..., \n",
       "          [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "          [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "          [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "   'data_dict': {'X_test': array([[ 0.50340514, -0.79835065,  0.54017334,  0.95680673, -0.80203568],\n",
       "           [ 0.88028284, -0.55409947,  0.72069563,  0.84432384, -0.51710945],\n",
       "           [-1.71352247,  1.70052685, -1.86362337,  0.14897507,  1.53164583],\n",
       "           ..., \n",
       "           [ 0.53665906, -0.51652236,  0.58767921,  0.04671789, -0.48997362],\n",
       "           [-0.09516531,  1.06171606, -0.09640523, -0.38276223,  0.94822545],\n",
       "           [ 1.26824517, -0.32863684,  1.30976834, -0.75088805, -0.28645488]]),\n",
       "    'X_train': array([[ 2.09959303, -1.1365446 ,  1.73732111, -0.07599071, -1.12766566],\n",
       "           [-1.65809928,  1.73810396, -2.03464448,  0.02626646,  1.66732499],\n",
       "           [-1.00410564,  1.26839014, -0.88500257,  0.03649218,  1.17888002],\n",
       "           ..., \n",
       "           [ 1.05763705, -2.5268975 ,  1.00573081,  1.31470683, -2.24023475],\n",
       "           [ 1.05763705, -0.81713921,  1.07223902,  0.7011638 , -0.70706027],\n",
       "           [-1.21471376,  1.86962382, -1.23654597, -2.78580579,  1.64018915]]),\n",
       "    'data_dict': {'X_test': array([[ 2.56841346,  0.14910704,  0.14637538, ...,  0.19895561,\n",
       "             -0.72312012, -0.44707028],\n",
       "            [ 0.68793991,  1.77512593,  0.61177048, ...,  0.64360435,\n",
       "             -0.80232083, -0.83443477],\n",
       "            [-0.09559074, -0.31546979,  3.11973298, ...,  0.05073936,\n",
       "              0.64969225,  0.75375966],\n",
       "            ..., \n",
       "            [-0.09559074,  0.48094763, -0.24145387, ...,  0.34717186,\n",
       "              0.96649511,  0.40513161],\n",
       "            [-0.25229687,  0.84597228,  0.22394123, ..., -0.91266625,\n",
       "             -0.77592059,  0.13397647],\n",
       "            [-1.03582751,  1.07826069,  0.53420463, ...,  0.42127998,\n",
       "             -0.80232083,  0.36639516]]),\n",
       "     'X_train': array([[-0.72241526,  0.84597228, -1.3015205 , ...,  1.38468559,\n",
       "             -0.01031369,  0.05650357],\n",
       "            [-0.409003  , -1.31099156,  0.68933633, ..., -0.76445   ,\n",
       "              1.07209606,  0.44386806],\n",
       "            [-1.34923977, -3.40158727,  1.30986313, ...,  1.16236122,\n",
       "             -0.85512131, -0.17591513],\n",
       "            ..., \n",
       "            [-1.81935816, -0.64731038, -0.42244086, ...,  1.45879372,\n",
       "             -1.4095263 ,  0.40513161],\n",
       "            [-0.409003  , -1.47691185,  0.24979651, ..., -0.24569313,\n",
       "              0.22728845,  0.71502321],\n",
       "            [ 0.53123378,  0.34821139,  0.66348105, ..., -0.09747689,\n",
       "             -1.09272345, -0.09844223]]),\n",
       "     'y_test': 32      1\n",
       "     1180    1\n",
       "     1466   -1\n",
       "     463    -1\n",
       "     1560   -1\n",
       "     1866   -1\n",
       "     925     1\n",
       "     856    -1\n",
       "     1614   -1\n",
       "     949     1\n",
       "     402     1\n",
       "     852    -1\n",
       "     8       1\n",
       "     150    -1\n",
       "     1481    1\n",
       "     297    -1\n",
       "     1580    1\n",
       "     1431   -1\n",
       "     1124   -1\n",
       "     726    -1\n",
       "     1857   -1\n",
       "     1803   -1\n",
       "     1382    1\n",
       "     692     1\n",
       "     469     1\n",
       "     293     1\n",
       "     729     1\n",
       "     427     1\n",
       "     356     1\n",
       "     1271    1\n",
       "            ..\n",
       "     394     1\n",
       "     327     1\n",
       "     1350   -1\n",
       "     98     -1\n",
       "     1639    1\n",
       "     1816   -1\n",
       "     164     1\n",
       "     1662   -1\n",
       "     229     1\n",
       "     946     1\n",
       "     465     1\n",
       "     975    -1\n",
       "     366    -1\n",
       "     67      1\n",
       "     1922    1\n",
       "     616     1\n",
       "     1806   -1\n",
       "     213     1\n",
       "     1210    1\n",
       "     970    -1\n",
       "     987    -1\n",
       "     1772    1\n",
       "     13     -1\n",
       "     1294    1\n",
       "     618     1\n",
       "     1464   -1\n",
       "     1133    1\n",
       "     400     1\n",
       "     1033    1\n",
       "     157    -1\n",
       "     Name: label, dtype: int64,\n",
       "     'y_train': 833     1\n",
       "     263    -1\n",
       "     1961    1\n",
       "     1157   -1\n",
       "     640    -1\n",
       "     214    -1\n",
       "     549     1\n",
       "     614     1\n",
       "     1691   -1\n",
       "     85     -1\n",
       "     414    -1\n",
       "     1895   -1\n",
       "     695    -1\n",
       "     167     1\n",
       "     5       1\n",
       "     1528    1\n",
       "     1176    1\n",
       "     344    -1\n",
       "     1699    1\n",
       "     948     1\n",
       "     1473    1\n",
       "     1470    1\n",
       "     832     1\n",
       "     472    -1\n",
       "     1098   -1\n",
       "     793    -1\n",
       "     981    -1\n",
       "     416     1\n",
       "     1559    1\n",
       "     1818   -1\n",
       "            ..\n",
       "     1689   -1\n",
       "     1147    1\n",
       "     1012   -1\n",
       "     77     -1\n",
       "     1421   -1\n",
       "     595    -1\n",
       "     183    -1\n",
       "     1415    1\n",
       "     1469   -1\n",
       "     1353   -1\n",
       "     1169    1\n",
       "     486    -1\n",
       "     1633   -1\n",
       "     1908   -1\n",
       "     1490   -1\n",
       "     1026    1\n",
       "     937    -1\n",
       "     955    -1\n",
       "     1215   -1\n",
       "     631     1\n",
       "     1549    1\n",
       "     1548   -1\n",
       "     1263    1\n",
       "     447    -1\n",
       "     895     1\n",
       "     1955    1\n",
       "     1583   -1\n",
       "     21      1\n",
       "     1457   -1\n",
       "     1752    1\n",
       "     Name: label, dtype: int64},\n",
       "    'transformer': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "    'y_test': 32      1\n",
       "    1180    1\n",
       "    1466   -1\n",
       "    463    -1\n",
       "    1560   -1\n",
       "    1866   -1\n",
       "    925     1\n",
       "    856    -1\n",
       "    1614   -1\n",
       "    949     1\n",
       "    402     1\n",
       "    852    -1\n",
       "    8       1\n",
       "    150    -1\n",
       "    1481    1\n",
       "    297    -1\n",
       "    1580    1\n",
       "    1431   -1\n",
       "    1124   -1\n",
       "    726    -1\n",
       "    1857   -1\n",
       "    1803   -1\n",
       "    1382    1\n",
       "    692     1\n",
       "    469     1\n",
       "    293     1\n",
       "    729     1\n",
       "    427     1\n",
       "    356     1\n",
       "    1271    1\n",
       "           ..\n",
       "    394     1\n",
       "    327     1\n",
       "    1350   -1\n",
       "    98     -1\n",
       "    1639    1\n",
       "    1816   -1\n",
       "    164     1\n",
       "    1662   -1\n",
       "    229     1\n",
       "    946     1\n",
       "    465     1\n",
       "    975    -1\n",
       "    366    -1\n",
       "    67      1\n",
       "    1922    1\n",
       "    616     1\n",
       "    1806   -1\n",
       "    213     1\n",
       "    1210    1\n",
       "    970    -1\n",
       "    987    -1\n",
       "    1772    1\n",
       "    13     -1\n",
       "    1294    1\n",
       "    618     1\n",
       "    1464   -1\n",
       "    1133    1\n",
       "    400     1\n",
       "    1033    1\n",
       "    157    -1\n",
       "    Name: label, dtype: int64,\n",
       "    'y_train': 833     1\n",
       "    263    -1\n",
       "    1961    1\n",
       "    1157   -1\n",
       "    640    -1\n",
       "    214    -1\n",
       "    549     1\n",
       "    614     1\n",
       "    1691   -1\n",
       "    85     -1\n",
       "    414    -1\n",
       "    1895   -1\n",
       "    695    -1\n",
       "    167     1\n",
       "    5       1\n",
       "    1528    1\n",
       "    1176    1\n",
       "    344    -1\n",
       "    1699    1\n",
       "    948     1\n",
       "    1473    1\n",
       "    1470    1\n",
       "    832     1\n",
       "    472    -1\n",
       "    1098   -1\n",
       "    793    -1\n",
       "    981    -1\n",
       "    416     1\n",
       "    1559    1\n",
       "    1818   -1\n",
       "           ..\n",
       "    1689   -1\n",
       "    1147    1\n",
       "    1012   -1\n",
       "    77     -1\n",
       "    1421   -1\n",
       "    595    -1\n",
       "    183    -1\n",
       "    1415    1\n",
       "    1469   -1\n",
       "    1353   -1\n",
       "    1169    1\n",
       "    486    -1\n",
       "    1633   -1\n",
       "    1908   -1\n",
       "    1490   -1\n",
       "    1026    1\n",
       "    937    -1\n",
       "    955    -1\n",
       "    1215   -1\n",
       "    631     1\n",
       "    1549    1\n",
       "    1548   -1\n",
       "    1263    1\n",
       "    447    -1\n",
       "    895     1\n",
       "    1955    1\n",
       "    1583   -1\n",
       "    21      1\n",
       "    1457   -1\n",
       "    1752    1\n",
       "    Name: label, dtype: int64},\n",
       "   'test_score': 0.68200000000000005,\n",
       "   'train_score': 0.77533333333333332,\n",
       "   'transformer': SelectKBest(k=5, score_func=<function f_classif at 0x116f989b0>),\n",
       "   'y_test': 32      1\n",
       "   1180    1\n",
       "   1466   -1\n",
       "   463    -1\n",
       "   1560   -1\n",
       "   1866   -1\n",
       "   925     1\n",
       "   856    -1\n",
       "   1614   -1\n",
       "   949     1\n",
       "   402     1\n",
       "   852    -1\n",
       "   8       1\n",
       "   150    -1\n",
       "   1481    1\n",
       "   297    -1\n",
       "   1580    1\n",
       "   1431   -1\n",
       "   1124   -1\n",
       "   726    -1\n",
       "   1857   -1\n",
       "   1803   -1\n",
       "   1382    1\n",
       "   692     1\n",
       "   469     1\n",
       "   293     1\n",
       "   729     1\n",
       "   427     1\n",
       "   356     1\n",
       "   1271    1\n",
       "          ..\n",
       "   394     1\n",
       "   327     1\n",
       "   1350   -1\n",
       "   98     -1\n",
       "   1639    1\n",
       "   1816   -1\n",
       "   164     1\n",
       "   1662   -1\n",
       "   229     1\n",
       "   946     1\n",
       "   465     1\n",
       "   975    -1\n",
       "   366    -1\n",
       "   67      1\n",
       "   1922    1\n",
       "   616     1\n",
       "   1806   -1\n",
       "   213     1\n",
       "   1210    1\n",
       "   970    -1\n",
       "   987    -1\n",
       "   1772    1\n",
       "   13     -1\n",
       "   1294    1\n",
       "   618     1\n",
       "   1464   -1\n",
       "   1133    1\n",
       "   400     1\n",
       "   1033    1\n",
       "   157    -1\n",
       "   Name: label, dtype: int64,\n",
       "   'y_train': 833     1\n",
       "   263    -1\n",
       "   1961    1\n",
       "   1157   -1\n",
       "   640    -1\n",
       "   214    -1\n",
       "   549     1\n",
       "   614     1\n",
       "   1691   -1\n",
       "   85     -1\n",
       "   414    -1\n",
       "   1895   -1\n",
       "   695    -1\n",
       "   167     1\n",
       "   5       1\n",
       "   1528    1\n",
       "   1176    1\n",
       "   344    -1\n",
       "   1699    1\n",
       "   948     1\n",
       "   1473    1\n",
       "   1470    1\n",
       "   832     1\n",
       "   472    -1\n",
       "   1098   -1\n",
       "   793    -1\n",
       "   981    -1\n",
       "   416     1\n",
       "   1559    1\n",
       "   1818   -1\n",
       "          ..\n",
       "   1689   -1\n",
       "   1147    1\n",
       "   1012   -1\n",
       "   77     -1\n",
       "   1421   -1\n",
       "   595    -1\n",
       "   183    -1\n",
       "   1415    1\n",
       "   1469   -1\n",
       "   1353   -1\n",
       "   1169    1\n",
       "   486    -1\n",
       "   1633   -1\n",
       "   1908   -1\n",
       "   1490   -1\n",
       "   1026    1\n",
       "   937    -1\n",
       "   955    -1\n",
       "   1215   -1\n",
       "   631     1\n",
       "   1549    1\n",
       "   1548   -1\n",
       "   1263    1\n",
       "   447    -1\n",
       "   895     1\n",
       "   1955    1\n",
       "   1583   -1\n",
       "   21      1\n",
       "   1457   -1\n",
       "   1752    1\n",
       "   Name: label, dtype: int64},\n",
       "  'model': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "             weights='uniform'),\n",
       "  'test_score': 0.68200000000000005,\n",
       "  'train_score': 0.77533333333333332,\n",
       "  'y_test': 32      1\n",
       "  1180    1\n",
       "  1466   -1\n",
       "  463    -1\n",
       "  1560   -1\n",
       "  1866   -1\n",
       "  925     1\n",
       "  856    -1\n",
       "  1614   -1\n",
       "  949     1\n",
       "  402     1\n",
       "  852    -1\n",
       "  8       1\n",
       "  150    -1\n",
       "  1481    1\n",
       "  297    -1\n",
       "  1580    1\n",
       "  1431   -1\n",
       "  1124   -1\n",
       "  726    -1\n",
       "  1857   -1\n",
       "  1803   -1\n",
       "  1382    1\n",
       "  692     1\n",
       "  469     1\n",
       "  293     1\n",
       "  729     1\n",
       "  427     1\n",
       "  356     1\n",
       "  1271    1\n",
       "         ..\n",
       "  394     1\n",
       "  327     1\n",
       "  1350   -1\n",
       "  98     -1\n",
       "  1639    1\n",
       "  1816   -1\n",
       "  164     1\n",
       "  1662   -1\n",
       "  229     1\n",
       "  946     1\n",
       "  465     1\n",
       "  975    -1\n",
       "  366    -1\n",
       "  67      1\n",
       "  1922    1\n",
       "  616     1\n",
       "  1806   -1\n",
       "  213     1\n",
       "  1210    1\n",
       "  970    -1\n",
       "  987    -1\n",
       "  1772    1\n",
       "  13     -1\n",
       "  1294    1\n",
       "  618     1\n",
       "  1464   -1\n",
       "  1133    1\n",
       "  400     1\n",
       "  1033    1\n",
       "  157    -1\n",
       "  Name: label, dtype: int64,\n",
       "  'y_train': 833     1\n",
       "  263    -1\n",
       "  1961    1\n",
       "  1157   -1\n",
       "  640    -1\n",
       "  214    -1\n",
       "  549     1\n",
       "  614     1\n",
       "  1691   -1\n",
       "  85     -1\n",
       "  414    -1\n",
       "  1895   -1\n",
       "  695    -1\n",
       "  167     1\n",
       "  5       1\n",
       "  1528    1\n",
       "  1176    1\n",
       "  344    -1\n",
       "  1699    1\n",
       "  948     1\n",
       "  1473    1\n",
       "  1470    1\n",
       "  832     1\n",
       "  472    -1\n",
       "  1098   -1\n",
       "  793    -1\n",
       "  981    -1\n",
       "  416     1\n",
       "  1559    1\n",
       "  1818   -1\n",
       "         ..\n",
       "  1689   -1\n",
       "  1147    1\n",
       "  1012   -1\n",
       "  77     -1\n",
       "  1421   -1\n",
       "  595    -1\n",
       "  183    -1\n",
       "  1415    1\n",
       "  1469   -1\n",
       "  1353   -1\n",
       "  1169    1\n",
       "  486    -1\n",
       "  1633   -1\n",
       "  1908   -1\n",
       "  1490   -1\n",
       "  1026    1\n",
       "  937    -1\n",
       "  955    -1\n",
       "  1215   -1\n",
       "  631     1\n",
       "  1549    1\n",
       "  1548   -1\n",
       "  1263    1\n",
       "  447    -1\n",
       "  895     1\n",
       "  1955    1\n",
       "  1583   -1\n",
       "  21      1\n",
       "  1457   -1\n",
       "  1752    1\n",
       "  Name: label, dtype: int64},\n",
       " 'model': GridSearchCV(cv=None, error_score='raise',\n",
       "        estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "            weights='uniform'),\n",
       "        fit_params={}, iid=True, n_jobs=1,\n",
       "        param_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "        scoring=None, verbose=0),\n",
       " 'test_score': 0.68200000000000005,\n",
       " 'train_score': 0.77533333333333332,\n",
       " 'y_test': 32      1\n",
       " 1180    1\n",
       " 1466   -1\n",
       " 463    -1\n",
       " 1560   -1\n",
       " 1866   -1\n",
       " 925     1\n",
       " 856    -1\n",
       " 1614   -1\n",
       " 949     1\n",
       " 402     1\n",
       " 852    -1\n",
       " 8       1\n",
       " 150    -1\n",
       " 1481    1\n",
       " 297    -1\n",
       " 1580    1\n",
       " 1431   -1\n",
       " 1124   -1\n",
       " 726    -1\n",
       " 1857   -1\n",
       " 1803   -1\n",
       " 1382    1\n",
       " 692     1\n",
       " 469     1\n",
       " 293     1\n",
       " 729     1\n",
       " 427     1\n",
       " 356     1\n",
       " 1271    1\n",
       "        ..\n",
       " 394     1\n",
       " 327     1\n",
       " 1350   -1\n",
       " 98     -1\n",
       " 1639    1\n",
       " 1816   -1\n",
       " 164     1\n",
       " 1662   -1\n",
       " 229     1\n",
       " 946     1\n",
       " 465     1\n",
       " 975    -1\n",
       " 366    -1\n",
       " 67      1\n",
       " 1922    1\n",
       " 616     1\n",
       " 1806   -1\n",
       " 213     1\n",
       " 1210    1\n",
       " 970    -1\n",
       " 987    -1\n",
       " 1772    1\n",
       " 13     -1\n",
       " 1294    1\n",
       " 618     1\n",
       " 1464   -1\n",
       " 1133    1\n",
       " 400     1\n",
       " 1033    1\n",
       " 157    -1\n",
       " Name: label, dtype: int64,\n",
       " 'y_train': 833     1\n",
       " 263    -1\n",
       " 1961    1\n",
       " 1157   -1\n",
       " 640    -1\n",
       " 214    -1\n",
       " 549     1\n",
       " 614     1\n",
       " 1691   -1\n",
       " 85     -1\n",
       " 414    -1\n",
       " 1895   -1\n",
       " 695    -1\n",
       " 167     1\n",
       " 5       1\n",
       " 1528    1\n",
       " 1176    1\n",
       " 344    -1\n",
       " 1699    1\n",
       " 948     1\n",
       " 1473    1\n",
       " 1470    1\n",
       " 832     1\n",
       " 472    -1\n",
       " 1098   -1\n",
       " 793    -1\n",
       " 981    -1\n",
       " 416     1\n",
       " 1559    1\n",
       " 1818   -1\n",
       "        ..\n",
       " 1689   -1\n",
       " 1147    1\n",
       " 1012   -1\n",
       " 77     -1\n",
       " 1421   -1\n",
       " 595    -1\n",
       " 183    -1\n",
       " 1415    1\n",
       " 1469   -1\n",
       " 1353   -1\n",
       " 1169    1\n",
       " 486    -1\n",
       " 1633   -1\n",
       " 1908   -1\n",
       " 1490   -1\n",
       " 1026    1\n",
       " 937    -1\n",
       " 955    -1\n",
       " 1215   -1\n",
       " 631     1\n",
       " 1549    1\n",
       " 1548   -1\n",
       " 1263    1\n",
       " 447    -1\n",
       " 895     1\n",
       " 1955    1\n",
       " 1583   -1\n",
       " 21      1\n",
       " 1457   -1\n",
       " 1752    1\n",
       " Name: label, dtype: int64}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_params={'n_neighbors':[3,5,7,9,11,13,15,17,19]}\n",
    "\n",
    "grid_searchknn = GridSearchCV(KNeighborsClassifier(), param_grid=gs_params)\n",
    "general_model(grid_searchknn, KNN_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77533333333333332, 0.68200000000000005)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNNGS=general_model(grid_searchknn, KNN_data_dict)\n",
    "KNNGS['train_score'], KNNGS['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNbest=KNNGS['model']\n",
    "KNbest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003148</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>0.812667</td>\n",
       "      <td>3</td>\n",
       "      <td>{u'n_neighbors': 3}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>0.010209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>5</td>\n",
       "      <td>{u'n_neighbors': 5}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.003091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.759000</td>\n",
       "      <td>7</td>\n",
       "      <td>{u'n_neighbors': 7}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.008602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>9</td>\n",
       "      <td>{u'n_neighbors': 9}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.003859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.691333</td>\n",
       "      <td>0.744667</td>\n",
       "      <td>11</td>\n",
       "      <td>{u'n_neighbors': 11}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.007214</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.734000</td>\n",
       "      <td>13</td>\n",
       "      <td>{u'n_neighbors': 13}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.021685</td>\n",
       "      <td>0.006164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.005330</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>15</td>\n",
       "      <td>{u'n_neighbors': 15}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.024386</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.687333</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>17</td>\n",
       "      <td>{u'n_neighbors': 17}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.001247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>19</td>\n",
       "      <td>{u'n_neighbors': 19}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.025351</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.003148         0.004287         0.677333          0.812667   \n",
       "1       0.003773         0.006189         0.696000          0.776667   \n",
       "2       0.003951         0.006795         0.692000          0.759000   \n",
       "3       0.003135         0.007066         0.686667          0.751667   \n",
       "4       0.004429         0.006750         0.691333          0.744667   \n",
       "5       0.003123         0.007214         0.686667          0.734000   \n",
       "6       0.003046         0.005330         0.686000          0.731000   \n",
       "7       0.002523         0.005683         0.687333          0.726667   \n",
       "8       0.002401         0.005554         0.686000          0.721000   \n",
       "\n",
       "  param_n_neighbors                params  rank_test_score  split0_test_score  \\\n",
       "0                 3   {u'n_neighbors': 3}                9              0.678   \n",
       "1                 5   {u'n_neighbors': 5}                1              0.678   \n",
       "2                 7   {u'n_neighbors': 7}                2              0.666   \n",
       "3                 9   {u'n_neighbors': 9}                5              0.656   \n",
       "4                11  {u'n_neighbors': 11}                3              0.668   \n",
       "5                13  {u'n_neighbors': 13}                5              0.656   \n",
       "6                15  {u'n_neighbors': 15}                7              0.652   \n",
       "7                17  {u'n_neighbors': 17}                4              0.646   \n",
       "8                19  {u'n_neighbors': 19}                7              0.656   \n",
       "\n",
       "   split0_train_score  split1_test_score  split1_train_score  \\\n",
       "0               0.804              0.682               0.827   \n",
       "1               0.781              0.702               0.774   \n",
       "2               0.770              0.708               0.749   \n",
       "3               0.757              0.702               0.748   \n",
       "4               0.747              0.708               0.747   \n",
       "5               0.741              0.702               0.735   \n",
       "6               0.735              0.708               0.730   \n",
       "7               0.728              0.722               0.727   \n",
       "8               0.726              0.718               0.718   \n",
       "\n",
       "   split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "0              0.672               0.807      0.000932        0.000613   \n",
       "1              0.708               0.775      0.000652        0.000411   \n",
       "2              0.702               0.758      0.000998        0.001227   \n",
       "3              0.702               0.750      0.000719        0.001378   \n",
       "4              0.698               0.740      0.001182        0.000633   \n",
       "5              0.702               0.726      0.001295        0.000809   \n",
       "6              0.698               0.728      0.000931        0.000469   \n",
       "7              0.694               0.725      0.000668        0.000104   \n",
       "8              0.684               0.719      0.000438        0.000435   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.004110         0.010209  \n",
       "1        0.012961         0.003091  \n",
       "2        0.018547         0.008602  \n",
       "3        0.021685         0.003859  \n",
       "4        0.016997         0.003300  \n",
       "5        0.021685         0.006164  \n",
       "6        0.024386         0.002944  \n",
       "7        0.031383         0.001247  \n",
       "8        0.025351         0.003559  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(KNbest.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
